"""
Daily Market Executive Report Generator
ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ë° ìë™í™” ë¦¬í¬íŒ… íŒŒì´í”„ë¼ì¸
"""
import os
import sys
import io
from pathlib import Path
from datetime import datetime
import pandas as pd
import json
import math
import numpy as np
from typing import List, Dict, Any, Optional
from openai import OpenAI
import google.generativeai as genai
from tenacity import retry, stop_after_attempt, wait_exponential

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv()

from config import get_config
from database import DatabaseManager
from modules.prompt_loader import PromptLoader
from modules.feedback_loader import FeedbackLoader
from modules.feedback_analyzer import FeedbackAnalyzer
import logging

logger = logging.getLogger(__name__)

# [ìˆ˜ì •] í…œí”Œë¦¿ í¬ë§·íŒ… ì‹œ í‚¤ê°€ ì—†ì–´ë„ ì—ëŸ¬ê°€ ë‚˜ì§€ ì•Šë„ë¡ í•˜ëŠ” ì•ˆì „í•œ ë”•ì…”ë„ˆë¦¬
class SafeDict(dict):
    def __missing__(self, key):
        return f"{{{key}}}"  # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ {í‚¤ì´ë¦„} ê·¸ëŒ€ë¡œ ë¬¸ìë¡œ ì¶œë ¥


class DailyReportGenerator:
    """ì¼ì¼ ì‹œì¥ ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.config = get_config()
        self.db_manager = DatabaseManager()
        self.llm_config = self.config.get('llm', {})
        self.llm_provider = self.llm_config.get('provider', 'openai')
        self.prompt_loader = PromptLoader()  # í”„ë¡¬í”„íŠ¸ ë¡œë” ì´ˆê¸°í™”
        
        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if self.llm_provider == 'openai':
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                self.llm_client = OpenAI(api_key=api_key)
            else:
                self.llm_client = None
                print("âš ï¸  OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Mock ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        elif self.llm_provider == 'gemini':
            api_key = os.getenv('GEMINI_API_KEY')
            if api_key:
                genai.configure(api_key=api_key)
                self.llm_client = genai.GenerativeModel(self.llm_config.get('model', 'gemini-2.0-flash'))
            else:
                self.llm_client = None
                print("âš ï¸  GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Mock ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        else:
            self.llm_client = None
            print("âš ï¸  LLM í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Mock ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    
    def load_data(self, category_filter: Optional[List[str]] = None) -> pd.DataFrame:
        """
        Step 1: ë°ì´í„° ì „ì²˜ë¦¬
        ì´ìŠˆ-ë‰´ìŠ¤ ë§¤í•‘ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            category_filter: í•„í„°ë§í•  ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì¹´í…Œê³ ë¦¬)
        
        Returns:
            í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„
        """
        print("=" * 80)
        print("Step 1: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬")
        if category_filter:
            print(f"ì¹´í…Œê³ ë¦¬ í•„í„°: {', '.join(category_filter)}")
        print("=" * 80)
        
        with self.db_manager.get_connection() as conn:
            query = """
                SELECT 
                    n.category_name,
                    i.id as issue_id,
                    i.title as issue_title,
                    m.news_id,
                    n.title as news_title,
                    n.source,
                    n.link,
                    n.importance_score,
                    n.user_feedback_score,
                    n.feedback_applied_to_importance,
                    n.published_at,
                    n.created_at
                FROM issue_news_mapping m
                JOIN issues i ON m.issue_id = i.id
                JOIN news n ON m.news_id = n.id
            """
            
            params = []
            if category_filter:
                placeholders = ','.join(['?' for _ in category_filter])
                query += f" WHERE n.category_name IN ({placeholders})"
                params = category_filter
            
            query += " ORDER BY i.id, n.importance_score DESC"
            df = pd.read_sql_query(query, conn, params=params)
        
        if df.empty:
            if category_filter:
                raise ValueError(f"í•„í„°ë§ëœ ì¹´í…Œê³ ë¦¬({', '.join(category_filter)})ì— ëŒ€í•œ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                raise ValueError("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"âœ… ì´ {len(df)}ê°œ ë§¤í•‘ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print(f"   - ì¹´í…Œê³ ë¦¬: {df['category_name'].unique().tolist()}")
        print(f"   - ì´ìŠˆ ìˆ˜: {df['issue_id'].nunique()}ê°œ")
        print()
        
        return df
    
    def preprocess_clusters(self, df: pd.DataFrame) -> Dict[str, List[Dict[str, Any]]]:
        """
        Step 1: í´ëŸ¬ìŠ¤í„°ë³„ ìƒìœ„ 5ê°œ ë‰´ìŠ¤ ì¶”ì¶œ
        - í´ëŸ¬ìŠ¤í„° ë‚´ ê¸°ì‚¬ ì„ íƒ: importance_score ê¸°ì¤€
        - ì„¹í„° ë¶„ì„ ìƒìœ„ í´ëŸ¬ìŠ¤í„° ì„ ì •: í´ëŸ¬ìŠ¤í„°ë§ ìŠ¤ì½”ì–´ ê¸°ì¤€ (avg_importanceÂ³ Ã— logâ‚‚(news_count + 1))
        """
        print("í´ëŸ¬ìŠ¤í„°ë³„ ìƒìœ„ 5ê°œ ë‰´ìŠ¤ ì¶”ì¶œ ì¤‘...")
        
        clusters = {}
        
        # category_nameê³¼ issue_title ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í•‘
        for (category, issue_title), group in df.groupby(['category_name', 'issue_title']):
            cluster_key = f"{category}::{issue_title}"
            issue_id = group.iloc[0]['issue_id']
            
            # í´ëŸ¬ìŠ¤í„° ë‚´ ê¸°ì‚¬ ì„ íƒ: importance_score ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            group_sorted = group.sort_values('importance_score', ascending=False)
            
            # ìƒìœ„ 5ê°œ ì¶”ì¶œ (importance_score ê¸°ì¤€)
            top_5 = group_sorted.head(5)
            
            # í´ëŸ¬ìŠ¤í„° ë°ì´í„° êµ¬ì„±
            cluster_data = {
                'category_name': category,
                'issue_title': issue_title,
                'issue_id': issue_id,
                'top_5_news': []
            }
            
            # í´ëŸ¬ìŠ¤í„°ë§ ìŠ¤ì½”ì–´ ê³„ì‚°: (avg_importanceÂ³ Ã— logâ‚‚(news_count + 1))
            # ì „ì²´ í´ëŸ¬ìŠ¤í„° ë‰´ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚° (ìƒìœ„ 5ê°œê°€ ì•„ë‹Œ ì „ì²´)
            avg_importance = float(group['importance_score'].mean())
            news_count = len(group)
            cluster_data['score'] = (avg_importance ** 3) * math.log2(news_count + 1)
            
            # ìƒìœ„ 5ê°œ ë‰´ìŠ¤ ì •ë³´ (importance_score ê¸°ì¤€)
            for _, row in top_5.iterrows():
                news_item = {
                    'title': row['news_title'],
                    'source': row['source'],
                    'link': row['link'],
                    'importance_score': float(row['importance_score']),
                    'user_feedback_score': float(row.get('user_feedback_score', 0.0)) if pd.notna(row.get('user_feedback_score')) else 0.0,
                    'feedback_applied_to_importance': bool(row.get('feedback_applied_to_importance', False)) if pd.notna(row.get('feedback_applied_to_importance')) else False,
                    'published_at': row['published_at'] if pd.notna(row['published_at']) else None,
                    'created_at': row['created_at'] if pd.notna(row['created_at']) else None
                }
                cluster_data['top_5_news'].append(news_item)
            
            clusters[cluster_key] = cluster_data
        
        print(f"âœ… {len(clusters)}ê°œ í´ëŸ¬ìŠ¤í„° ìƒì„± ì™„ë£Œ")
        print()
        
        return clusters
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    def analyze_cluster(self, cluster_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Step 2: Micro-Analysis (Cluster ë‹¨ìœ„ ë¶„ì„)
        ê° í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•´ LLMì„ í˜¸ì¶œí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        top_5_news = cluster_data['top_5_news']
        category = cluster_data['category_name']
        
        # ë‰´ìŠ¤ ì •ë³´ í¬ë§·íŒ…
        news_text = ""
        for i, news in enumerate(top_5_news, 1):
            date_str = "25.12.14"  # ê¸°ë³¸ê°’
            if news.get('published_at'):
                try:
                    if isinstance(news['published_at'], str):
                        dt = datetime.fromisoformat(news['published_at'].replace('Z', '+00:00'))
                    else:
                        dt = news['published_at']
                    date_str = dt.strftime("%y.%m.%d")
                except:
                    pass
            
            news_text += f"{i}. ì œëª©: {news['title']}\n"
            news_text += f"   ì¶œì²˜: {news['source']}\n"
            news_text += f"   ë§í¬: {news['link']}\n"
            news_text += f"   ë‚ ì§œ: {date_str}\n"
            news_text += f"   ì¤‘ìš”ë„: {news['importance_score']:.2f}\n\n"
        
        # í”„ë¡¬í”„íŠ¸ ë¡œë”ì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        default_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ 5ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

ì¹´í…Œê³ ë¦¬: {category}

ë‰´ìŠ¤ ê¸°ì‚¬:
{news_text}

ë‹¤ìŒ JSON êµ¬ì¡°ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "new_title": "5ê°œ ê¸°ì‚¬ë¥¼ ì•„ìš°ë¥´ëŠ” í†µì°°ë ¥ ìˆëŠ” ëŒ€í‘œ ì œëª© (ìˆ˜ì¹˜ í¬í•¨, ê±´ì¡°í•œ ë¶„ì„ê°€ í†¤)",
    "fact_check_analyst_view": "ì´ìŠˆì˜ ë°œìƒ ë°°ê²½, ì£¼ìš” ìˆ˜ì¹˜(ê¸ˆì•¡, ì§€ìˆ˜ ë“±), ì‹œì¥ ì˜í–¥ë ¥ì„ í¬í•¨í•œ 3~4ë¬¸ì¥ì˜ í•µì‹¬ ìš”ì•½",
    "selected_links": [
        "ìƒìœ„ 3~4ê°œ ê¸°ì‚¬ë¥¼ ì„ ì •í•˜ì—¬ ì•„ë˜ í¬ë§·ìœ¼ë¡œ ë³€í™˜",
        "ì˜ì–´ ê¸°ì‚¬: [yy.mm.dd] <í•œê¸€ ë²ˆì—­ ì œëª©> - [<ì›ë¬¸ ì œëª©>](<ë§í¬>)",
        "í•œêµ­ì–´ ê¸°ì‚¬: [yy.mm.dd] <ê¸°ì‚¬ ì œëª©> - [ë§í¬](<ë§í¬>)"
    ]
}}

ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•˜ë©°, ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”."""
        
        default_system = "ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  ê±´ì¡°í•œ í†¤ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
        
        prompt_data = self.prompt_loader.get_prompt(
            'micro_analysis',
            default_prompt=default_prompt,
            default_system=default_system,
            category=category,
            news_text=news_text
        )
        
        prompt = prompt_data['prompt']
        system_prompt = prompt_data.get('system_prompt') or default_system

        # LLM í˜¸ì¶œ
        if self.llm_client is None:
            # Mock ì‘ë‹µ
            return {
                'new_title': f"{cluster_data['issue_title']} (ë¶„ì„ í•„ìš”)",
                'fact_check_analyst_view': "LLM API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹¤ì œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.",
                'selected_links': [
                    f"[25.12.14] {news['title']} - [{news['title']}]({news['link']})"
                    for news in top_5_news[:3]
                ]
            }
        
        try:
            if self.llm_provider == 'openai':
                response = self.llm_client.chat.completions.create(
                    model=self.llm_config.get('model', 'gpt-4'),
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=self.llm_config.get('temperature', 0.3),
                    max_tokens=self.llm_config.get('max_tokens', 2000),
                    response_format={"type": "json_object"}
                )
                result_text = response.choices[0].message.content
            elif self.llm_provider == 'gemini':
                response = self.llm_client.generate_content(
                    f"{prompt}\n\nì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.",
                    generation_config=genai.types.GenerationConfig(
                        temperature=self.llm_config.get('temperature', 0.3),
                        max_output_tokens=self.llm_config.get('max_tokens', 2000),
                    )
                )
                result_text = response.text
            
            # JSON íŒŒì‹±
            # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
            result_text = result_text.strip()
            if result_text.startswith("```json"):
                result_text = result_text[7:]
            if result_text.startswith("```"):
                result_text = result_text[3:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
            result_text = result_text.strip()
            
            result = json.loads(result_text)
            
            # selected_links í¬ë§·íŒ…
            formatted_links = []
            for news in top_5_news[:4]:  # ìƒìœ„ 4ê°œ
                date_str = "25.12.14"
                if news.get('published_at'):
                    try:
                        if isinstance(news['published_at'], str):
                            dt = datetime.fromisoformat(news['published_at'].replace('Z', '+00:00'))
                        else:
                            dt = news['published_at']
                        date_str = dt.strftime("%y.%m.%d")
                    except:
                        pass
                
                # ì–¸ì–´ ê°ì§€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
                is_korean = any(ord(char) >= 0xAC00 and ord(char) <= 0xD7A3 for char in news['title'])
                
                if is_korean:
                    formatted_links.append(f"[{date_str}] {news['title']} - [ë§í¬]({news['link']})")
                else:
                    formatted_links.append(f"[{date_str}] {news['title']} - [{news['title']}]({news['link']})")
            
            result['selected_links'] = formatted_links
            
            return result
            
        except Exception as e:
            print(f"âš ï¸  LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            # Fallback
            return {
                'new_title': cluster_data['issue_title'],
                'fact_check_analyst_view': "LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                'selected_links': [
                    f"[25.12.14] {news['title']} - [{news['title']}]({news['link']})"
                    for news in top_5_news[:3]
                ]
            }
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    def consolidate_themes(self, analyzed_results: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """
        Step 2: Theme Consolidation (í•µì‹¬ ë‹¨ê³„)
        íŒŒí¸í™”ëœ ì´ìŠˆë“¤ì„ í•˜ë‚˜ì˜ ê±°ëŒ€í•œ í…Œë§ˆë¡œ ë³‘í•©í•©ë‹ˆë‹¤.
        """
        print("=" * 80)
        print("Step 2: Theme Consolidation (í…Œë§ˆ í†µí•©)")
        print("=" * 80)
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í•‘
        categories = {}
        for result in analyzed_results:
            category = result['category_name']
            if category not in categories:
                categories[category] = []
            categories[category].append(result)
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        for category in categories:
            categories[category].sort(key=lambda x: x['score'], reverse=True)
        
        # ì¹´í…Œê³ ë¦¬ë³„ í…Œë§ˆ í†µí•©
        consolidated_themes = {}
        
        for category, results in categories.items():
            print(f"\n[{category}] í…Œë§ˆ í†µí•© ì¤‘...")
            
            # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            analysis_list = ""
            for i, result in enumerate(results, 1):
                analysis_list += f"{i}. ì œëª©: {result['new_title']}\n"
                analysis_list += f"   ìš”ì•½: {result['fact_check_analyst_view']}\n"
                analysis_list += f"   ì ìˆ˜: {result['score']:.2f}\n\n"
            
            # í”„ë¡¬í”„íŠ¸ ë¡œë”ì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
            default_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ {category} ì¹´í…Œê³ ë¦¬ì˜ ë¶„ì„ ê²°ê³¼ë“¤ì„ ê²€í† í•˜ì—¬ í…Œë§ˆë¥¼ í†µí•©í•´ì£¼ì„¸ìš”.

[ì§€ì‹œì‚¬í•­]
1. **Grouping:** ë‚´ìš©ì´ ìœ ì‚¬í•œ í•˜ìœ„ ì´ìŠˆë“¤ì„ í•˜ë‚˜ì˜ ë©”ì¸ í…Œë§ˆ(Main Theme)ë¡œ ë¬¶ì–´ì£¼ì„¸ìš”.
   - ì˜ˆ) "ì—°ì¤€ ê¸ˆë¦¬ ì¸í•˜", "íŒŒì›” ë°œì–¸", "ë§¤íŒŒì  ì¸í•˜", "3íšŒ ì—°ì† ì¸í•˜" -> [Theme 1: ë¯¸ ì—°ì¤€ ê¸ˆë¦¬ ì¸í•˜ì™€ í–¥í›„ ì •ì±… ê²½ë¡œ]ë¡œ í†µí•©
   - ì˜ˆ) "ì½”ìŠ¤í”¼ ê¸°ê´€ ë§¤ìˆ˜", "ë„¤ ë§ˆë…€ì˜ ë‚ ", "4160ì„  íšŒë³µ" -> [Theme 2: ë„¤ ë§ˆë…€ì˜ ë‚  ìˆ˜ê¸‰ ê³µë°©ê³¼ ê¸°ê´€ì˜ ë°©ì–´]ë¡œ í†µí•©

2. **Filtering:** ê°€ì¥ ì¤‘ìš”í•œ Top 2~3ê°œì˜ ë©”ì¸ í…Œë§ˆë§Œ ì„ ë³„í•˜ì„¸ìš”. (ì ìˆ˜ê°€ ë‚®ê±°ë‚˜ ìì˜í•œ ì´ìŠˆëŠ” ê³¼ê°íˆ ì œì™¸í•˜ê±°ë‚˜ ë©”ì¸ í…Œë§ˆì˜ ê·¼ê±°ë¡œ í¸ì…)

3. **No Repetition:** ì ˆëŒ€ ê°™ì€ ì‚¬ê±´(ì˜ˆ: ê¸ˆë¦¬ ì¸í•˜)ì„ ë‘ ê°œì˜ ì„¹ì…˜ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì“°ì§€ ë§ˆì„¸ìš”. ë¬´ì¡°ê±´ í•˜ë‚˜ë¡œ í•©ì¹˜ì„¸ìš”.

[ë¶„ì„ ê²°ê³¼]
{analysis_list}

ë‹¤ìŒ JSON êµ¬ì¡°ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "themes": [
        {{
            "theme_title": "ë©”ì¸ í…Œë§ˆ ì œëª©",
            "related_issue_indices": [1, 3, 5],
            "deep_dive": "í†µí•©ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ìƒì„¸ ë¶„ì„ (ë°°ê²½, ìˆ˜ì¹˜, ì „ë§ í¬í•¨ 5~6ë¬¸ì¥)"
        }}
    ]
}}

ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•˜ë©°, ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”."""
            
            default_system = "ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  ê±´ì¡°í•œ í†¤ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
            
            prompt_data = self.prompt_loader.get_prompt(
                'theme_consolidation',
                default_prompt=default_prompt,
                default_system=default_system,
                category=category,
                analysis_list=analysis_list
            )
            
            prompt = prompt_data['prompt']
            system_prompt = prompt_data.get('system_prompt') or default_system
            
            # LLM í˜¸ì¶œ
            if self.llm_client is None:
                # Mock: ìƒìœ„ 2ê°œë§Œ ì„ íƒ
                top_2 = results[:2]
                themes = []
                for result in top_2:
                    themes.append({
                        'theme_title': result['new_title'],
                        'related_issue_indices': [results.index(result)],
                        'deep_dive': result['fact_check_analyst_view']
                    })
                consolidated_themes[category] = themes
            else:
                try:
                    if self.llm_provider == 'openai':
                        response = self.llm_client.chat.completions.create(
                            model=self.llm_config.get('model', 'gpt-4'),
                            messages=[
                                {"role": "system", "content": system_prompt},
                                {"role": "user", "content": prompt}
                            ],
                            temperature=self.llm_config.get('temperature', 0.3),
                            max_tokens=self.llm_config.get('max_tokens', 2000),
                            response_format={"type": "json_object"}
                        )
                        result_text = response.choices[0].message.content
                    elif self.llm_provider == 'gemini':
                        response = self.llm_client.generate_content(
                            f"{prompt}\n\nì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.",
                            generation_config=genai.types.GenerationConfig(
                                temperature=self.llm_config.get('temperature', 0.3),
                                max_output_tokens=self.llm_config.get('max_tokens', 2000),
                            )
                        )
                        result_text = response.text
                    
                    # JSON íŒŒì‹±
                    result_text = result_text.strip()
                    if result_text.startswith("```json"):
                        result_text = result_text[7:]
                    if result_text.startswith("```"):
                        result_text = result_text[3:]
                    if result_text.endswith("```"):
                        result_text = result_text[:-3]
                    result_text = result_text.strip()
                    
                    consolidation_result = json.loads(result_text)
                    themes = consolidation_result.get('themes', [])
                    
                    # ì¸ë±ìŠ¤ë¥¼ ì‹¤ì œ ê²°ê³¼ë¡œ ë³€í™˜
                    consolidated_list = []
                    for theme in themes[:3]:  # ìµœëŒ€ 3ê°œ
                        related_results = []
                        for idx in theme.get('related_issue_indices', []):
                            if 0 <= idx - 1 < len(results):  # 1-based to 0-based
                                related_results.append(results[idx - 1])
                        
                        if related_results:
                            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ê²°ê³¼ë¥¼ ëŒ€í‘œë¡œ ì‚¬ìš©
                            main_result = max(related_results, key=lambda x: x['score'])
                            consolidated_list.append({
                                'theme_title': theme.get('theme_title', main_result['new_title']),
                                'deep_dive': theme.get('deep_dive', main_result['fact_check_analyst_view']),
                                'related_results': related_results,
                                'score': main_result['score']
                            })
                    
                    consolidated_themes[category] = consolidated_list
                    print(f"   âœ… {len(consolidated_list)}ê°œ ë©”ì¸ í…Œë§ˆ ìƒì„±")
                    
                except Exception as e:
                    print(f"âš ï¸  í…Œë§ˆ í†µí•© ì‹¤íŒ¨: {e}, ìƒìœ„ 2ê°œë§Œ ì„ íƒí•©ë‹ˆë‹¤.")
                    # Fallback: ìƒìœ„ 2ê°œë§Œ ì„ íƒ
                    top_2 = results[:2]
                    consolidated_list = []
                    for result in top_2:
                        consolidated_list.append({
                            'theme_title': result['new_title'],
                            'deep_dive': result['fact_check_analyst_view'],
                            'related_results': [result],
                            'score': result['score']
                        })
                    consolidated_themes[category] = consolidated_list
        
        print()
        return consolidated_themes
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    def generate_final_report(self, consolidated_themes: Dict[str, List[Dict[str, Any]]], 
                             sections: Optional[List[str]] = None) -> str:
        """
        Step 3: Final Report Generation
        í†µí•©ëœ í…Œë§ˆë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            consolidated_themes: í†µí•©ëœ í…Œë§ˆ ë”•ì…”ë„ˆë¦¬
            sections: ì‚¬ìš©í•  ì„¹ì…˜ ID ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì„¹ì…˜ ì‚¬ìš©)
        """
        print("=" * 80)
        print("Step 3: ìµœì¢… ë³´ê³ ì„œ ìƒì„±")
        print("=" * 80)
        
        # ì „ì²´ í…Œë§ˆ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
        themes_summary = ""
        for category, themes in consolidated_themes.items():
            themes_summary += f"\n## {category}\n\n"
            for theme in themes:
                themes_summary += f"**{theme['theme_title']}**\n"
                themes_summary += f"{theme['deep_dive']}\n\n"
        
        # í”„ë¡¬í”„íŠ¸ ë¡œë”ì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        default_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ í†µí•©ëœ í…Œë§ˆ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ Executive Summaryì™€ Investor Noteë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

í†µí•©ëœ í…Œë§ˆ ë¶„ì„:
{themes_summary}

ë‹¤ìŒ JSON êµ¬ì¡°ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "executive_summary": {{
        "global": "ê¸€ë¡œë²Œ ì‹œì¥ ê´€ì ì—ì„œ í•µì‹¬ 1ì¤„ ìš”ì•½",
        "korea": "í•œêµ­ ì‹œì¥ ê´€ì ì—ì„œ í•µì‹¬ 1ì¤„ ìš”ì•½",
        "key_indicator": "ì£¼ìš” ì§€í‘œ ê´€ì ì—ì„œ í•µì‹¬ 1ì¤„ ìš”ì•½"
    }},
    "investor_note": {{
        "caution": "ê²½ê³„í•´ì•¼ í•  ë¦¬ìŠ¤í¬ ìš”ì•½ (2~3ë¬¸ì¥)",
        "action": "ëŒ€ì‘ ì „ëµ ì œì–¸ (2~3ë¬¸ì¥)"
    }}
}}

ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•˜ë©°, ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”."""
        
        default_system = "ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  ê±´ì¡°í•œ í†¤ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
        
        prompt_data = self.prompt_loader.get_prompt(
            'final_report',
            default_prompt=default_prompt,
            default_system=default_system,
            themes_summary=themes_summary
        )
        
        prompt = prompt_data['prompt']
        system_prompt = prompt_data.get('system_prompt') or default_system

        # LLM í˜¸ì¶œ
        if self.llm_client is None:
            # Mock ì‘ë‹µ
            executive_summary = {
                'global': 'ê¸€ë¡œë²Œ ì‹œì¥ ë¶„ì„ í•„ìš”',
                'korea': 'í•œêµ­ ì‹œì¥ ë¶„ì„ í•„ìš”',
                'key_indicator': 'ì£¼ìš” ì§€í‘œ ë¶„ì„ í•„ìš”'
            }
            investor_note = {
                'caution': 'LLM API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ìƒì„¸ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'action': 'ì‹¤ì œ API í‚¤ë¥¼ ì„¤ì •í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.'
            }
        else:
            try:
                if self.llm_provider == 'openai':
                    response = self.llm_client.chat.completions.create(
                        model=self.llm_config.get('model', 'gpt-4'),
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=self.llm_config.get('temperature', 0.3),
                        max_tokens=self.llm_config.get('max_tokens', 2000),
                        response_format={"type": "json_object"}
                    )
                    result_text = response.choices[0].message.content
                elif self.llm_provider == 'gemini':
                    response = self.llm_client.generate_content(
                        f"{prompt}\n\nì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.",
                        generation_config=genai.types.GenerationConfig(
                            temperature=self.llm_config.get('temperature', 0.3),
                            max_output_tokens=self.llm_config.get('max_tokens', 2000),
                        )
                    )
                    result_text = response.text
                
                # JSON íŒŒì‹±
                result_text = result_text.strip()
                if result_text.startswith("```json"):
                    result_text = result_text[7:]
                if result_text.startswith("```"):
                    result_text = result_text[3:]
                if result_text.endswith("```"):
                    result_text = result_text[:-3]
                result_text = result_text.strip()
                
                result = json.loads(result_text)
                executive_summary = result.get('executive_summary', {})
                investor_note = result.get('investor_note', {})
                
            except Exception as e:
                print(f"âš ï¸  ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
                executive_summary = {
                    'global': 'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ',
                    'korea': 'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ',
                    'key_indicator': 'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ'
                }
                investor_note = {
                    'caution': 'LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
                    'action': 'ë°ì´í„°ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
                }
        
        # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ë³´ê³ ì„œ ì–‘ì‹ ë¡œë“œ ì‹œë„
        from modules.settings_loader import SettingsLoader
        settings_loader = SettingsLoader()
        report_template = settings_loader.get_report_template()
        
        # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì–‘ì‹ì´ ìˆê³  sectionsê°€ ì§€ì •ëœ ê²½ìš°
        if report_template and sections:
            return self._generate_report_with_template(
                report_template, sections, consolidated_themes, 
                executive_summary, investor_note
            )
        elif report_template:
            # sectionsê°€ ì—†ìœ¼ë©´ ëª¨ë“  ì„¹ì…˜ ì‚¬ìš©
            all_sections = sorted(report_template.keys(), 
                                 key=lambda x: report_template[x].get('order', 999))
            return self._generate_report_with_template(
                report_template, all_sections, consolidated_themes,
                executive_summary, investor_note
            )
        else:
            # ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš© (ê¸°ì¡´ ì½”ë“œ)
            return self._generate_report_with_default_template(
                consolidated_themes, executive_summary, investor_note
            )
    
    def _generate_report_with_template(self, template: Dict[str, Dict[str, Any]], 
                                      sections: List[str],
                                      consolidated_themes: Dict[str, List[Dict[str, Any]]],
                                      executive_summary: Dict[str, str],
                                      investor_note: Dict[str, str]) -> str:
        """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ë³´ê³ ì„œ ìƒì„± (SafeDict ì ìš©)"""
        report_parts = []
        date_short = datetime.now().strftime("%Y.%m.%d")
        generated_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # sectionsë¥¼ order ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_sections = sorted(
            [s for s in sections if s in template],
            key=lambda x: template[x].get('order', 999)
        )
        
        i = 0
        while i < len(sorted_sections):
            section_id = sorted_sections[i]
            section_data = template[section_id]
            template_text = section_data['template']
            
            # [ìˆ˜ì •] ê° ì„¹ì…˜ë³„ë¡œ í•„ìš”í•œ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“¤ê³  SafeDictë¡œ ê°ì‹¸ì„œ format_map ì‚¬ìš©
            if section_id == 'a':  # header
                context = {'date_short': date_short}
                report_parts.append(template_text.format_map(SafeDict(context)) + "\n\n")
                
            elif section_id == 'b':  # executive_summary
                context = {
                    'executive_summary_global': executive_summary.get('global', 'N/A'),
                    'executive_summary_korea': executive_summary.get('korea', 'N/A'),
                    'executive_summary_key_indicator': executive_summary.get('key_indicator', 'N/A')
                }
                report_parts.append(template_text.format_map(SafeDict(context)) + "\n\n")
                
            elif section_id == 'c':  # sector_analysis_header
                report_parts.append(template_text)
                
            elif section_id == 'd':  # category_header
                # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë°˜ë³µ
                for category, themes in consolidated_themes.items():
                    context = {'category': category}
                    report_parts.append(template_text.format_map(SafeDict(context)) + "\n")
                    # ë‹¤ìŒ ì„¹ì…˜ë“¤ë„ ì²˜ë¦¬ (e, f, g)
                    category_parts, i = self._process_category_sections(
                        template, sorted_sections, themes, 
                        i, date_short
                    )
                    report_parts.extend(category_parts)
                continue  # continueë¡œ ë‹¤ìŒ ë£¨í”„ë¡œ
                
            elif section_id == 'h':  # investor_note
                context = {
                    'investor_note_caution': investor_note.get('caution', 'N/A'),
                    'investor_note_action': investor_note.get('action', 'N/A')
                }
                report_parts.append(template_text.format_map(SafeDict(context)) + "\n\n")
                
            elif section_id == 'i':  # footer
                context = {'generated_time': generated_time}
                report_parts.append(template_text.format_map(SafeDict(context)))
            
            i += 1
        
        return "".join(report_parts)
    
    def _process_category_sections(self, template: Dict, 
                                   sections: List[str], themes: List[Dict],
                                   current_idx: int, date_short: str) -> tuple:
        """ì¹´í…Œê³ ë¦¬ ë‚´ë¶€ ì„¹ì…˜ ì²˜ë¦¬ (e, f, g) - (ìƒì„±ëœ ë¶€ë¶„ ë¦¬ìŠ¤íŠ¸, ë‹¤ìŒ ì¸ë±ìŠ¤) ë°˜í™˜"""
        category_sections = ['e', 'f', 'g']
        idx = current_idx + 1
        parts = []
        
        for theme in themes:
            # e, f, g ì„¹ì…˜ ì²˜ë¦¬
            for section_id in category_sections:
                if idx >= len(sections) or sections[idx] != section_id:
                    continue
                    
                if section_id == 'e':  # theme_section
                    context = {
                        'theme_title': theme['theme_title'],
                        'deep_dive': theme['deep_dive']
                    }
                    parts.append(template[section_id]['template'].format_map(SafeDict(context)) + "\n")
                    idx += 1
                    
                elif section_id == 'f':  # key_news
                    key_news_list = self._format_key_news(theme, date_short)
                    if key_news_list:
                        context = {'key_news_list': key_news_list}
                        parts.append(template[section_id]['template'].format_map(SafeDict(context)) + "\n")
                    idx += 1
                    
                elif section_id == 'g':  # feedback_section
                    feedback_list = self._format_feedback_news(theme, date_short)
                    if feedback_list:
                        context = {'feedback_news_list': feedback_list}
                        parts.append(template[section_id]['template'].format_map(SafeDict(context)) + "\n")
                    idx += 1
        
        return parts, idx
    
    def _format_key_news(self, theme: Dict, date_short: str) -> str:
        """Key News í¬ë§·íŒ…"""
        all_news = []
        for result in theme['related_results']:
            if 'top_5_news' in result:
                for news in result.get('top_5_news', []):
                    all_news.append(news)
        
        if not all_news:
            return ""
        
        all_news.sort(key=lambda x: x.get('importance_score', 0), reverse=True)
        top_news = all_news[:4]
        
        news_list = []
        for news in top_news:
            date_str = "25.12.14"
            if news.get('published_at'):
                try:
                    if isinstance(news['published_at'], str):
                        dt = datetime.fromisoformat(news['published_at'].replace('Z', '+00:00'))
                    else:
                        dt = news['published_at']
                    date_str = dt.strftime("%y.%m.%d")
                except:
                    pass
            
            is_korean = any(ord(char) >= 0xAC00 and ord(char) <= 0xD7A3 for char in news['title'])
            
            if is_korean:
                news_list.append(f"- [{date_str}] {news['title']} - [ë§í¬]({news['link']})")
            else:
                korean_title = news['title']  # ì‹¤ì œë¡œëŠ” LLM ë²ˆì—­ í•„ìš”
                news_list.append(f"- [{date_str}] {korean_title} - [{news['title']}]({news['link']})")
        
        return "\n".join(news_list)
    
    def _format_feedback_news(self, theme: Dict, date_short: str) -> str:
        """Feedback News í¬ë§·íŒ…"""
        all_news = []
        for result in theme['related_results']:
            if 'top_5_news' in result:
                for news in result.get('top_5_news', []):
                    all_news.append(news)
        
        if not all_news:
            return ""
        
        all_news.sort(key=lambda x: x.get('importance_score', 0), reverse=True)
        top_news = all_news[:4]
        
        # í”¼ë“œë°± ì ìˆ˜ê°€ ìˆëŠ” ë‰´ìŠ¤ ë³„ë„ ìˆ˜ì§‘
        feedback_news = []
        top_news_ids = {news.get('link', '') for news in top_news}
        for news in all_news:
            if news.get('user_feedback_score', 0.0) > 0.0:
                if news.get('link', '') not in top_news_ids:
                    feedback_news.append(news)
        
        if not feedback_news:
            return ""
        
        feedback_news.sort(key=lambda x: x.get('user_feedback_score', 0.0), reverse=True)
        feedback_news = feedback_news[:2]
        
        # í”¼ë“œë°± ë¡œë“œ
        feedbacks = []
        try:
            feedback_loader = FeedbackLoader()
            feedbacks = feedback_loader.get_all()
        except Exception as e:
            logger.warning(f"í”¼ë“œë°± ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        if not feedbacks:
            return ""
        
        feedback_list = []
        feedback_analyzer = FeedbackAnalyzer()
        
        for news in feedback_news:
            date_str = "25.12.14"
            if news.get('published_at'):
                try:
                    if isinstance(news['published_at'], str):
                        dt = datetime.fromisoformat(news['published_at'].replace('Z', '+00:00'))
                    else:
                        dt = news['published_at']
                    date_str = dt.strftime("%y.%m.%d")
                except:
                    pass
            
            is_korean = any(ord(char) >= 0xAC00 and ord(char) <= 0xD7A3 for char in news['title'])
            
            if is_korean:
                news_line = f"- [{date_str}] {news['title']} - [ë§í¬]({news['link']})"
            else:
                korean_title = news['title']
                news_line = f"- [{date_str}] {korean_title} - [{news['title']}]({news['link']})"
            
            # ë§¤ì¹­ëœ í”¼ë“œë°± ì½”ë©˜íŠ¸
            news_text = f"{news.get('title', '')} {news.get('snippet', '')}"
            news_embedding = feedback_analyzer.generate_embedding(news_text)
            
            matched_comments = []
            if news_embedding is not None:
                for feedback in feedbacks:
                    feedback_text = f"{feedback.get('news_title', '')} {feedback.get('user_comment', '')}"
                    feedback_embedding = feedback_analyzer.generate_embedding(feedback_text)
                    if feedback_embedding is not None:
                        similarity = feedback_analyzer.calculate_similarity(
                            feedback_embedding, 
                            np.array([news_embedding])
                        )[0]
                        if similarity >= 0.7:
                            matched_comments.append(feedback.get('user_comment', ''))
            
            feedback_list.append(news_line)
            if matched_comments:
                feedback_list.append("  \n  **ğŸ’¬ ì‚¬ìš©ì í”¼ë“œë°±:**")
                for comment in matched_comments:
                    feedback_list.append(f"  - {comment}")
        
        return "\n".join(feedback_list)
    
    def _generate_report_with_default_template(self, consolidated_themes: Dict[str, List[Dict[str, Any]]],
                                               executive_summary: Dict[str, str],
                                               investor_note: Dict[str, str]) -> str:
        """ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš© (í˜„ì¬ ì½”ë“œ ê·¸ëŒ€ë¡œ)"""
        # Markdown ë¦¬í¬íŠ¸ ìƒì„±
        today = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
        date_short = datetime.now().strftime("%Y.%m.%d")
        report = f"""# ğŸ“… Daily Market Executive Report

Date: {date_short}

## Executive Summary

- **Global:** {executive_summary.get('global', 'N/A')}
- **Korea:** {executive_summary.get('korea', 'N/A')}
- **Key Indicator:** {executive_summary.get('key_indicator', 'N/A')}

---

## Sector Analysis

"""
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì„¹ì…˜ ì‘ì„±
        for category, themes in consolidated_themes.items():
            report += f"### {category}\n\n"
            
            for theme in themes:
                # Main Theme Title
                report += f"#### {theme['theme_title']}\n\n"
                
                # Deep Dive
                report += f"**Deep Dive:**\n{theme['deep_dive']}\n\n"
                
                # Key News: importance_score ê¸°ì¤€ ìƒìœ„ 3~4ê°œë§Œ ì„ íƒ
                all_news = []
                for result in theme['related_results']:
                    # ì›ë³¸ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
                    if 'top_5_news' in result:
                        for news in result.get('top_5_news', []):
                            all_news.append(news)
                
                # importance_score ê¸°ì¤€ ì •ë ¬ ë° ìƒìœ„ 3~4ê°œ ì„ íƒ
                if all_news:
                    all_news.sort(key=lambda x: x.get('importance_score', 0), reverse=True)
                    top_news = all_news[:4]  # ìƒìœ„ 4ê°œ
                    
                    # í”¼ë“œë°± ì ìˆ˜ê°€ ìˆëŠ” ë‰´ìŠ¤ ë³„ë„ ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±°)
                    feedback_news = []
                    top_news_ids = {news.get('link', '') for news in top_news}
                    for news in all_news:
                        if news.get('user_feedback_score', 0.0) > 0.0:
                            # Key Newsì— í¬í•¨ë˜ì§€ ì•Šì€ í”¼ë“œë°± ë‰´ìŠ¤ë§Œ ì¶”ê°€
                            if news.get('link', '') not in top_news_ids:
                                feedback_news.append(news)
                    
                    # í”¼ë“œë°± ë‰´ìŠ¤ë¥¼ user_feedback_score ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ 2ê°œë§Œ ì„ íƒ
                    feedback_news.sort(key=lambda x: x.get('user_feedback_score', 0.0), reverse=True)
                    feedback_news = feedback_news[:2]
                    
                    # í”¼ë“œë°± ë¡œë“œ
                    feedback_loader = None
                    feedbacks = []
                    try:
                        feedback_loader = FeedbackLoader()
                        feedbacks = feedback_loader.get_all()
                    except Exception as e:
                        logger.warning(f"í”¼ë“œë°± ë¡œë“œ ì‹¤íŒ¨: {e}")
                    
                    report += "**ğŸ“° Key News:**\n"
                    for news in top_news:
                        date_str = "25.12.14"
                        if news.get('published_at'):
                            try:
                                if isinstance(news['published_at'], str):
                                    dt = datetime.fromisoformat(news['published_at'].replace('Z', '+00:00'))
                                else:
                                    dt = news['published_at']
                                date_str = dt.strftime("%y.%m.%d")
                            except:
                                pass
                        
                        # ì–¸ì–´ ê°ì§€
                        is_korean = any(ord(char) >= 0xAC00 and ord(char) <= 0xD7A3 for char in news['title'])
                        
                        if is_korean:
                            # í•œêµ­ì–´ ê¸°ì‚¬: [ë‚ ì§œ] <ê¸°ì‚¬ ì œëª©> - [ë§í¬](<ë§í¬>)
                            report += f"- [{date_str}] {news['title']} - [ë§í¬]({news['link']})\n"
                        else:
                            # ì˜ì–´ ê¸°ì‚¬: [ë‚ ì§œ] <í•œê¸€ ë²ˆì—­ ì œëª©> - [<ì›ë¬¸ ì œëª©>](<ë§í¬>)
                            korean_title = news['title']  # ì‹¤ì œë¡œëŠ” LLM ë²ˆì—­ í•„ìš”
                            report += f"- [{date_str}] {korean_title} - [{news['title']}]({news['link']})\n"
                    
                    # í”¼ë“œë°± ë‰´ìŠ¤ê°€ ìˆìœ¼ë©´ ë³„ë„ ì„¹ì…˜ ì¶”ê°€
                    if feedback_news and feedbacks:
                        report += "\n**ğŸ” ì¶”ê°€ ê´€ì  (ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜):**\n"
                        feedback_analyzer = FeedbackAnalyzer()
                        
                        for news in feedback_news:
                            date_str = "25.12.14"
                            if news.get('published_at'):
                                try:
                                    if isinstance(news['published_at'], str):
                                        dt = datetime.fromisoformat(news['published_at'].replace('Z', '+00:00'))
                                    else:
                                        dt = news['published_at']
                                    date_str = dt.strftime("%y.%m.%d")
                                except:
                                    pass
                            
                            # ì–¸ì–´ ê°ì§€
                            is_korean = any(ord(char) >= 0xAC00 and ord(char) <= 0xD7A3 for char in news['title'])
                            
                            if is_korean:
                                report += f"- [{date_str}] {news['title']} - [ë§í¬]({news['link']})\n"
                            else:
                                korean_title = news['title']
                                report += f"- [{date_str}] {korean_title} - [{news['title']}]({news['link']})\n"
                            
                            # ë§¤ì¹­ëœ í”¼ë“œë°± ì½”ë©˜íŠ¸ í‘œì‹œ
                            # ë‰´ìŠ¤ í…ìŠ¤íŠ¸ë¡œ ì„ë² ë”© ìƒì„±
                            news_text = f"{news.get('title', '')} {news.get('snippet', '')}"
                            news_embedding = feedback_analyzer.generate_embedding(news_text)
                            
                            if news_embedding is not None:
                                matched_comments = []
                                for feedback in feedbacks:
                                    feedback_text = f"{feedback.get('news_title', '')} {feedback.get('user_comment', '')}"
                                    feedback_embedding = feedback_analyzer.generate_embedding(feedback_text)
                                    if feedback_embedding is not None:
                                        similarity = feedback_analyzer.calculate_similarity(
                                            feedback_embedding, 
                                            np.array([news_embedding])
                                        )[0]
                                        if similarity >= 0.7:
                                            matched_comments.append(feedback.get('user_comment', ''))
                                
                                if matched_comments:
                                    report += "  \n  **ğŸ’¬ ì‚¬ìš©ì í”¼ë“œë°±:**\n"
                                    for comment in matched_comments:
                                        report += f"  - {comment}\n"
                else:
                    # Fallback: selected_links ì‚¬ìš©
                    report += "**ğŸ“° Key News:**\n"
                    if theme['related_results']:
                        for link in theme['related_results'][0].get('selected_links', [])[:4]:
                            report += f"- {link}\n"
                
                report += "\n"
        
        report += f"""---

## Investor Note

### Caution
{investor_note.get('caution', 'N/A')}

### Action
{investor_note.get('action', 'N/A')}

---

*Report generated on {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""
        
        return report
    
    def save_report(self, report: str, filename: str = "daily_market_report.md"):
        """
        Step 4: ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        """
        print("=" * 80)
        print("Step 4: ë¦¬í¬íŠ¸ ì €ì¥")
        print("=" * 80)
        
        output_path = Path(project_root) / filename
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {output_path}")
        print()
    
    def run(self, category_filter: Optional[List[str]] = None, 
            report_name: Optional[str] = None, sections: Optional[List[str]] = None):
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            category_filter: í•„í„°ë§í•  ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì¹´í…Œê³ ë¦¬)
            report_name: ë³´ê³ ì„œ ì´ë¦„ (íŒŒì¼ëª…ì— ì‚¬ìš©)
            sections: ì‚¬ìš©í•  ì„¹ì…˜ ID ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì„¹ì…˜)
        """
        print("=" * 80)
        print("Daily Market Executive Report Generator")
        if category_filter:
            print(f"ë³´ê³ ì„œ ê·¸ë£¹: {', '.join(category_filter)}")
        print("=" * 80)
        print()
        
        try:
            # Step 1: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
            df = self.load_data(category_filter=category_filter)
            clusters = self.preprocess_clusters(df)
            
            if not clusters:
                print("âš ï¸  ë¶„ì„í•  í´ëŸ¬ìŠ¤í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # Step 2: Micro-Analysis
            print("=" * 80)
            print("Step 2: Micro-Analysis (Cluster ë‹¨ìœ„ ë¶„ì„)")
            print("=" * 80)
            
            analyzed_results = []
            for i, (cluster_key, cluster_data) in enumerate(clusters.items(), 1):
                print(f"[{i}/{len(clusters)}] ë¶„ì„ ì¤‘: {cluster_data['issue_title']}")
                result = self.analyze_cluster(cluster_data)
                result.update({
                    'category_name': cluster_data['category_name'],
                    'issue_title': cluster_data['issue_title'],
                    'score': cluster_data['score'],
                    'top_5_news': cluster_data['top_5_news']  # ì›ë³¸ ë‰´ìŠ¤ ë°ì´í„° ë³´ì¡´
                })
                analyzed_results.append(result)
                print(f"   âœ… ì™„ë£Œ: {result['new_title']}")
            
            print()
            
            # Step 2-2: Theme Consolidation
            consolidated_themes = self.consolidate_themes(analyzed_results)
            
            # Step 3: Final Report Generation
            report = self.generate_final_report(consolidated_themes, sections=sections)
            
            # Step 4: ì €ì¥
            if report_name:
                filename = f"{report_name}.md"
            else:
                filename = "daily_market_report.md"
            self.save_report(report, filename=filename)
            
            print("=" * 80)
            print("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
            print("=" * 80)
            
            return report
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def run_by_groups(self):
        """
        ë³´ê³ ì„œ ê·¸ë£¹ë³„ë¡œ ë³´ê³ ì„œ ìƒì„±
        ì„¤ì • íŒŒì¼ì˜ report_groupsì— ë”°ë¼ ì—¬ëŸ¬ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        """
        report_groups = self.config.get('report_groups', [])
        
        if not report_groups:
            # ë³´ê³ ì„œ ê·¸ë£¹ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰
            print("ë³´ê³ ì„œ ê·¸ë£¹ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ í•˜ë‚˜ì˜ ë³´ê³ ì„œë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            print()
            return self.run()
        
        print("=" * 80)
        print(f"ë³´ê³ ì„œ ê·¸ë£¹ë³„ ìƒì„±: {len(report_groups)}ê°œ ê·¸ë£¹")
        print("=" * 80)
        print()
        
        reports = {}
        for i, group in enumerate(report_groups, 1):
            group_name = group.get('name', f'Group {i}')
            categories = group.get('categories', [])
            output_file = group.get('output_file', f"{group_name.lower().replace(' ', '_')}.md")
            sections_str = group.get('sections', '')  # ìƒˆë¡œ ì¶”ê°€
            
            # sections íŒŒì‹± (ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ)
            sections = None
            if sections_str:
                sections = [s.strip() for s in sections_str.split(',') if s.strip()]
            
            if not categories:
                print(f"âš ï¸  [{group_name}] ì¹´í…Œê³ ë¦¬ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            print(f"[{i}/{len(report_groups)}] {group_name} ìƒì„± ì¤‘...")
            print(f"   ì¹´í…Œê³ ë¦¬: {', '.join(categories)}")
            if sections:
                print(f"   ì„¹ì…˜: {', '.join(sections)}")
            print()
            
            try:
                report = self.run(category_filter=categories, 
                                report_name=group_name, 
                                sections=sections)  # sections ì „ë‹¬
                if report:
                    reports[group_name] = {
                        'content': report,
                        'output_file': output_file
                    }
                    print(f"âœ… [{group_name}] ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_file}")
                else:
                    print(f"âš ï¸  [{group_name}] ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨ (ë°ì´í„° ì—†ìŒ)")
            except Exception as e:
                print(f"âŒ [{group_name}] ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
                logger.error(f"ë³´ê³ ì„œ ê·¸ë£¹ '{group_name}' ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            
            print()
        
        print("=" * 80)
        print(f"ë³´ê³ ì„œ ê·¸ë£¹ë³„ ìƒì„± ì™„ë£Œ: {len(reports)}/{len(report_groups)}ê°œ ì„±ê³µ")
        print("=" * 80)
        
        return reports


if __name__ == "__main__":
    generator = DailyReportGenerator()
    
    # ë³´ê³ ì„œ ê·¸ë£¹ì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ê·¸ë£¹ë³„ë¡œ ìƒì„±, ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹
    report_groups = generator.config.get('report_groups', [])
    if report_groups:
        generator.run_by_groups()
    else:
        generator.run()
